{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58595fe4-a5c3-4629-b743-1c49e2fa4613",
   "metadata": {},
   "source": [
    "## Atividade 03 - Análise de Série Temporal com Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b9e58-fd45-4dbd-966c-06074bcf198a",
   "metadata": {},
   "source": [
    "## Parte 1 - Tratando e arrumando os dados\n",
    "\n",
    "Essa primeira parte eu fiz para o laboratório, por isso o ambiente virtual utilizado é diferente. Coloquei para mostrar como foi feito o tratamento de dados que resultou em uma planilha única com mais de 400k de linhas de dados sobre movimentação de resíduos sólidos no município de Florianópolis dos anos de 2016 a 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2e1811-e70c-4f6c-b055-2620a5397fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.linear_model import TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba17b61-5771-4f56-a9b8-26489137097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho da pasta que contém as planilhas\n",
    "caminho_pasta = r'C:\\Users\\CPDI\\Documents\\GitHub\\LARESO_Python\\Dados_Entrada'\n",
    "caminho_saida = r'C:\\Users\\CPDI\\Documents\\GitHub\\LARESO_Python\\Dados_Saida'\n",
    "\n",
    "# Garantir que a pasta de saída exista\n",
    "os.makedirs(caminho_saida, exist_ok=True)\n",
    "\n",
    "# Anos a serem processados\n",
    "anos = list(range(2016, 2023))\n",
    "\n",
    "# Processar as planilhas para cada ano\n",
    "for ano in anos:\n",
    "    # Carregar a planilha Gerador\n",
    "    caminho_planilhagerador = os.path.join(caminho_pasta, f'gerador florianópolis {ano}.xlsx')\n",
    "    planilhagerador = pd.read_excel(caminho_planilhagerador, engine='openpyxl')\n",
    "\n",
    "    # Carregar a planilha Destinador\n",
    "    caminho_planilhadestinador = os.path.join(caminho_pasta, f'destinador florianópolis {ano}.xlsx')\n",
    "    planilhadestinador = pd.read_excel(caminho_planilhadestinador, engine='openpyxl')\n",
    "\n",
    "    # Excluir as linhas onde \"NOME MUNICIPIO GERADOR\" for igual a \"NOME MUNICIPIO DESTINADOR\"\n",
    "    planilhagerador_sem_duplicatas = planilhagerador[planilhagerador['NOME MUNICIPIO GERADOR'] != planilhagerador['NOME MUNICIPIO DESTINADOR']]\n",
    "\n",
    "    # Unir a planilha Gerador (sem duplicatas) com a planilha Destinador\n",
    "    planilha_unida = pd.concat([planilhagerador_sem_duplicatas, planilhadestinador], ignore_index=True)\n",
    "\n",
    "    # Salvar a planilha sem duplicatas e a união no formato .xlsx\n",
    "    caminho_saida_planilhagerador = os.path.join(caminho_saida, f'gerador_florianópolis_{ano}_Sem_Duplicatas.xlsx')\n",
    "    caminho_saida_planilha_unida = os.path.join(caminho_saida, f'Planilha_Unida_{ano}.xlsx')\n",
    "\n",
    "    # Salvar a planilha Gerador sem duplicatas\n",
    "    planilhagerador_sem_duplicatas.to_excel(caminho_saida_planilhagerador, index=False, engine='openpyxl')\n",
    "\n",
    "    # Salvar a planilha unida (Gerador sem duplicatas + Destinador)\n",
    "    planilha_unida.to_excel(caminho_saida_planilha_unida, index=False, engine='openpyxl')\n",
    "\n",
    "    print(f'Processamento do ano {ano} concluído. Arquivos salvos: {caminho_saida_planilhagerador} e {caminho_saida_planilha_unida}')\n",
    "\n",
    "# Definir o caminho da pasta onde as planilhas sem duplicatas e unidas foram salvas\n",
    "caminho_pasta = r'C:\\Users\\CPDI\\Documents\\GitHub\\LARESO_Python\\Dados_Saida'\n",
    "caminho_pasta_entrada = r'C:\\Users\\CPDI\\Documents\\GitHub\\LARESO_Python\\Dados_Entrada'\n",
    "\n",
    "# Anos a serem verificados\n",
    "anos = list(range(2016, 2023))\n",
    "\n",
    "# Verificar as planilhas para cada ano\n",
    "for ano in anos:\n",
    "    # Carregar a planilha Gerador sem duplicatas\n",
    "    caminho_planilhagerador_sem_duplicatas = os.path.join(caminho_pasta, f'gerador_florianópolis_{ano}_Sem_Duplicatas.xlsx')\n",
    "    planilhagerador_sem_duplicatas = pd.read_excel(caminho_planilhagerador_sem_duplicatas, engine='openpyxl')\n",
    "\n",
    "    # Carregar a planilha Destinador\n",
    "    caminho_planilhadestinador = os.path.join(caminho_pasta_entrada, f'destinador florianópolis {ano}.xlsx')\n",
    "    planilhadestinador = pd.read_excel(caminho_planilhadestinador, engine='openpyxl')\n",
    "\n",
    "    # Carregar a planilha unida\n",
    "    caminho_planilha_unida = os.path.join(caminho_pasta, f'Planilha_Unida_{ano}.xlsx')\n",
    "    planilha_unida = pd.read_excel(caminho_planilha_unida, engine='openpyxl')\n",
    "\n",
    "    # Contar o número de linhas da planilha Gerador (sem duplicatas)\n",
    "    linhas_gerador_sem_duplicatas = planilhagerador_sem_duplicatas.shape[0]\n",
    "    \n",
    "    # Contar o número de linhas da planilha Destinador\n",
    "    linhas_destinador = planilhadestinador.shape[0]\n",
    "    \n",
    "    # Contar o número de linhas da planilha unida\n",
    "    linhas_unidas = planilha_unida.shape[0]\n",
    "\n",
    "    # Verificar se o número de linhas unidas é igual à soma das linhas das duas planilhas\n",
    "    linhas_esperadas = linhas_gerador_sem_duplicatas + linhas_destinador\n",
    "\n",
    "    # Exibir as informações pra confirmar que foi feito tudo certo\n",
    "    print(f'Ano {ano}:')\n",
    "    print(f'Linhas na planilha Gerador (sem duplicatas): {linhas_gerador_sem_duplicatas}')\n",
    "    print(f'Linhas na planilha Destinador: {linhas_destinador}')\n",
    "    print(f'Soma esperada: {linhas_esperadas}')\n",
    "    print(f'Linhas na planilha unida: {linhas_unidas}')\n",
    "\n",
    "    # Verificar se a união está correta\n",
    "    if linhas_unidas == linhas_esperadas:\n",
    "        print(f'União das planilhas de {ano} está correta.\\n')\n",
    "    else:\n",
    "        print(f'Erro na união das planilhas de {ano}. Linhas unidas: {linhas_unidas}, esperado: {linhas_esperadas}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5fef7-f14b-4bfc-898b-8fdce634427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as planilhas unidas de todos os anos\n",
    "todas_planilhas_unidas = []\n",
    "\n",
    "# Carregar cada planilha unida de cada ano\n",
    "for ano in anos:\n",
    "    # Caminho da planilha unida do ano atual\n",
    "    caminho_planilha_unida = os.path.join(caminho_saida, f'Planilha_Unida_{ano}.xlsx')\n",
    "    \n",
    "    # Verificar se a planilha unida existe\n",
    "    if os.path.exists(caminho_planilha_unida):\n",
    "        # Carregar a planilha unida\n",
    "        planilha_unida = pd.read_excel(caminho_planilha_unida, engine='openpyxl')\n",
    "        \n",
    "        # Adicionar a coluna \"Ano\" para identificar o ano na planilha\n",
    "        planilha_unida['Ano'] = ano\n",
    "        \n",
    "        # Adicionar a planilha à lista\n",
    "        todas_planilhas_unidas.append(planilha_unida)\n",
    "        print(f'Planilha unida de {ano} carregada e adicionada à lista.')\n",
    "    else:\n",
    "        print(f'Planilha unida de {ano} não encontrada.')\n",
    "\n",
    "# Concatenar todas as planilhas unidas em uma única planilha\n",
    "if todas_planilhas_unidas:\n",
    "    planilha_unica = pd.concat(todas_planilhas_unidas, ignore_index=True)\n",
    "\n",
    "    # Salvar a planilha única em um arquivo Excel\n",
    "    caminho_saida_planilha_unica = os.path.join(caminho_saida, 'Planilha_Unica_Todos_Anos.xlsx')\n",
    "    planilha_unica.to_excel(caminho_saida_planilha_unica, index=False, engine='openpyxl')\n",
    "\n",
    "    print(f'Planilha única de todos os anos salva em: {caminho_saida_planilha_unica}')\n",
    "else:\n",
    "    print('Nenhuma planilha unida foi encontrada para criar a planilha única.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c79f4-9ce0-443f-9799-ce2a32845b79",
   "metadata": {},
   "source": [
    "## Parte 2 - Análise da Série Temporal (2016 - 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0763db-2444-4b13-b0fb-08645d5ea62f",
   "metadata": {},
   "source": [
    "Aqui eu mudei o nome da planilha tratada para \"dados_atv3\" e estou trabalhando no ambiente virtual da disciplina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8612d075-674b-4848-91b2-6450aa53b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA RECEBIMENTO MANIFESTO                        object\n",
      "%CODIGO MANIFESTO                                float64\n",
      "QUANTIDADE GERADOS RESIDUOS (TONELADAS)          float64\n",
      "QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)    float64\n",
      "TIPO RESIDUO 1                                    object\n",
      "TIPO RESIDUO 2                                    object\n",
      "TIPO RESIDUO 3                                    object\n",
      "CLASSE ITEM_MANIFESTO                             object\n",
      "TECNOLOGIA DESTINAÇÃO                             object\n",
      "CNPJ GERADOR                                      object\n",
      "NOME GERADOR                                      object\n",
      "NOME MUNICIPIO GERADOR                            object\n",
      "CNPJ DESTINADOR                                   object\n",
      "NOME DESTINADOR                                   object\n",
      "NOME MUNICIPIO DESTINADOR                         object\n",
      "Ano                                                int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Definir o caminho da pasta que contém a planilha geral \n",
    "path = r'C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\MTRs_Florianopolis.csv'\n",
    "path_fig_atv3 = r'C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3'\n",
    "\n",
    "data = pd.read_csv(path, sep=';', dtype={9: str, 12: str}) # Coluna 9 e 12 estavam dando problema então converti para string já que são textos\n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86ffd5c0-0ff1-422b-94fa-87225484ea15",
   "metadata": {},
   "source": [
    "A minha coluna \"DATA RECEBIMENTO MANIFESTO\" está no formato \"ano-mês-dia 00:00:00\", então vou arrumar primeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724beefa-4712-4b25-8d6e-6ccaabc52f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DATA RECEBIMENTO MANIFESTO  Dia  Mês     Ano\n",
      "0                        NaT  NaN  NaN     NaN\n",
      "1                 2016-01-04  4.0  1.0  2016.0\n",
      "2                 2016-01-04  4.0  1.0  2016.0\n",
      "3                 2016-01-04  4.0  1.0  2016.0\n",
      "4                 2016-01-04  4.0  1.0  2016.0\n"
     ]
    }
   ],
   "source": [
    "# Converter a coluna 'DATA RECEBIMENTO MANIFESTO' para o formato datetime, especificando o formato correto\n",
    "data['DATA RECEBIMENTO MANIFESTO'] = pd.to_datetime(\n",
    "    data['DATA RECEBIMENTO MANIFESTO'], \n",
    "    format='%d/%m/%Y %H:%M', \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Criar novas colunas para o dia, mês e ano, ignorando valores NaT\n",
    "data['Dia'] = data['DATA RECEBIMENTO MANIFESTO'].dt.day\n",
    "data['Mês'] = data['DATA RECEBIMENTO MANIFESTO'].dt.month\n",
    "data['Ano'] = data['DATA RECEBIMENTO MANIFESTO'].dt.year\n",
    "\n",
    "# Exibir as primeiras linhas para verificar o resultado\n",
    "print(data[['DATA RECEBIMENTO MANIFESTO', 'Dia', 'Mês', 'Ano']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff72b731-7da2-4e8a-8864-2f5cb009b08e",
   "metadata": {},
   "source": [
    "Análise da série temporal utilizando um lineplot com uma mancha com os valores mínimos e máximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b187a70-1aac-488f-8f6b-4cd310098188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA RECEBIMENTO MANIFESTO                       datetime64[ns]\n",
      "%CODIGO MANIFESTO                                       float64\n",
      "QUANTIDADE GERADOS RESIDUOS (TONELADAS)                 float64\n",
      "QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)           float64\n",
      "TIPO RESIDUO 1                                           object\n",
      "TIPO RESIDUO 2                                           object\n",
      "TIPO RESIDUO 3                                           object\n",
      "CLASSE ITEM_MANIFESTO                                    object\n",
      "TECNOLOGIA DESTINAÇÃO                                    object\n",
      "CNPJ GERADOR                                             object\n",
      "NOME GERADOR                                             object\n",
      "NOME MUNICIPIO GERADOR                                   object\n",
      "CNPJ DESTINADOR                                          object\n",
      "NOME DESTINADOR                                          object\n",
      "NOME MUNICIPIO DESTINADOR                                object\n",
      "Ano                                                     float64\n",
      "Dia                                                     float64\n",
      "Mês                                                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa91613-3de7-4439-a7ae-0f977f879839",
   "metadata": {},
   "source": [
    "Lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a75203fa-3c4a-46dd-a9af-99f4199ea975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figura de resíduos gerados salva em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\lineplot_gerados_Florianópolis.png\n",
      "Figura de resíduos destinados salva em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\lineplot_destinados_Florianópolis.png\n",
      "Figura de resíduos gerados e destinados salva em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\lineplot_gerados_destinados_Florianópolis.png\n"
     ]
    }
   ],
   "source": [
    "# Função para agregar resíduos por mês e ano, separando gerados e destinados\n",
    "def agregar_residuos(data):\n",
    "    # Criar colunas de 'Ano' e 'Mês' a partir da coluna de data\n",
    "    data['Ano'] = data['DATA RECEBIMENTO MANIFESTO'].dt.year\n",
    "    data['Mês'] = data['DATA RECEBIMENTO MANIFESTO'].dt.month\n",
    "\n",
    "    # Agregar resíduos gerados e destinados no mesmo DataFrame\n",
    "    residuos_mensais = data.groupby(['Ano', 'Mês'])[['QUANTIDADE GERADOS RESIDUOS (TONELADAS)', 'QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)']].sum().reset_index()\n",
    "    residuos_mensais['Data'] = pd.to_datetime(residuos_mensais.rename(columns={'Ano': 'year', 'Mês': 'month'}).assign(day=1)[['year', 'month', 'day']])\n",
    "\n",
    "    return residuos_mensais\n",
    "\n",
    "# Função para criar lineplot de resíduos gerados com faixa de mínimos e máximos gerais\n",
    "def lineplot_gerados(residuos_mensais, localidade, path_fig_atv3):\n",
    "    min_geral = residuos_mensais['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].min()\n",
    "    max_geral = residuos_mensais['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].max()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(residuos_mensais['Data'], residuos_mensais['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'], label='Gerados', color='blue')\n",
    "    plt.fill_between(residuos_mensais['Data'], min_geral, max_geral, color='skyblue', alpha=0.3, label='Faixa Min-Max Geral')\n",
    "    plt.title(f'Série Temporal de Resíduos Gerados (Mensal) - {localidade}')\n",
    "    plt.xlabel('Anos)')\n",
    "    plt.ylabel('Quantidade de Resíduos Gerados (Toneladas)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(axis='y', linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if not os.path.exists(path_fig_atv3):\n",
    "        os.makedirs(path_fig_atv3)\n",
    "\n",
    "    fig_name = os.path.join(path_fig_atv3, f'lineplot_gerados_{localidade}.png')\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Figura de resíduos gerados salva em: {fig_name}\")\n",
    "\n",
    "# Função para criar lineplot de resíduos destinados com faixa de mínimos e máximos gerais\n",
    "def lineplot_destinados(residuos_mensais, localidade, path_fig_atv3):\n",
    "    min_geral = residuos_mensais['QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)'].min()\n",
    "    max_geral = residuos_mensais['QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)'].max()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(residuos_mensais['Data'], residuos_mensais['QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)'], label='Destinados', color='green')\n",
    "    plt.fill_between(residuos_mensais['Data'], min_geral, max_geral, color='lightgreen', alpha=0.3, label='Faixa Min-Max Geral')\n",
    "    plt.title(f'Série Temporal de Resíduos Destinados (Mensal) - {localidade}')\n",
    "    plt.xlabel('Anos')\n",
    "    plt.ylabel('Quantidade de Resíduos Destinados (Toneladas)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(axis='y', linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_name = os.path.join(path_fig_atv3, f'lineplot_destinados_{localidade}.png')\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Figura de resíduos destinados salva em: {fig_name}\")\n",
    "\n",
    "# Função para criar lineplot de resíduos gerados e destinados juntos (sem faixa de mínimos e máximos)\n",
    "def lineplot_gerados_destinados(residuos_mensais, localidade, path_fig_atv3):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(residuos_mensais['Data'], residuos_mensais['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'], label='Gerados', color='blue')\n",
    "    plt.plot(residuos_mensais['Data'], residuos_mensais['QUANTIDADE DESTINADA RESIDUOS (TONELADAS) (1)'], label='Destinados', color='green')\n",
    "    plt.title(f'Série Temporal de Resíduos Gerados e Destinados (Mensal) - {localidade}')\n",
    "    plt.xlabel('Anos')\n",
    "    plt.ylabel('Quantidade de Resíduos (Toneladas)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(axis='y', linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_name = os.path.join(path_fig_atv3, f'lineplot_gerados_destinados_{localidade}.png')\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Figura de resíduos gerados e destinados salva em: {fig_name}\")\n",
    "\n",
    "# Executar a análise para Florianópolis\n",
    "analise_completa(data, 'Florianópolis', path_fig_atv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3353b4f-d8d1-4b46-928c-028081209081",
   "metadata": {},
   "source": [
    "Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b28b2f72-57c4-4e40-ad97-c4869a947d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot de resíduos gerados por mês salvo em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\boxplot_residuos_gerados_Florianópolis.png\n"
     ]
    }
   ],
   "source": [
    "# Função para agregar resíduos gerados por mês e ano\n",
    "def agregar_residuos_gerados(data):\n",
    "    data['Ano'] = data['DATA RECEBIMENTO MANIFESTO'].dt.year\n",
    "    data['Mês'] = data['DATA RECEBIMENTO MANIFESTO'].dt.month\n",
    "    residuos_mensais_gerados = data.groupby(['Ano', 'Mês'])['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].sum().reset_index()\n",
    "    return residuos_mensais_gerados\n",
    "\n",
    "# Função para criar boxplot de resíduos gerados por mês\n",
    "def boxplot_residuos_gerados_mensal(residuos_mensais_gerados, localidade, path_fig_atv3):\n",
    "    # Criar um boxplot para resíduos gerados por mês\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    residuos_mensais_gerados['Mês'] = residuos_mensais_gerados['Mês'].apply(lambda x: pd.to_datetime(x, format='%m').strftime('%b'))\n",
    "\n",
    "    # Criar o boxplot usando 'tick_labels'\n",
    "    plt.boxplot(\n",
    "        [residuos_mensais_gerados[residuos_mensais_gerados['Mês'] == mes]['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'] \n",
    "         for mes in residuos_mensais_gerados['Mês'].unique()],\n",
    "        tick_labels=residuos_mensais_gerados['Mês'].unique()\n",
    "    )\n",
    "\n",
    "    plt.title(f'Boxplot Mensal de Resíduos Gerados - {localidade}')\n",
    "    plt.xlabel('Mês')\n",
    "    plt.ylabel('Quantidade de Resíduos Gerados (Toneladas)')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', color='gray', alpha=0.1)\n",
    "\n",
    "    # Salvar figura\n",
    "    fig_name = os.path.join(path_fig_atv3, f'boxplot_residuos_gerados_{localidade}.png')\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Boxplot de resíduos gerados por mês salvo em: {fig_name}\")\n",
    "\n",
    "# Função principal para a análise completa\n",
    "def analise_boxplot_residuos_gerados(data, localidade, path_fig_atv3):\n",
    "    residuos_mensais_gerados = agregar_residuos_gerados(data)\n",
    "    boxplot_residuos_gerados_mensal(residuos_mensais_gerados, localidade, path_fig_atv3)\n",
    "\n",
    "# Executar a análise para Florianópolis\n",
    "analise_boxplot_residuos_gerados(data, 'Florianópolis', path_fig_atv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238ea0f-c37e-49ee-8b66-447f23572a13",
   "metadata": {},
   "source": [
    "Estatísticas univariadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47fe9d3f-6dcf-4f14-9348-f6b11b9cbb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas por dia da semana salvas em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\estatisticas_dia_semana.csv\n",
      "Estatísticas por mês salvas em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\estatisticas_mes.csv\n",
      "Estatísticas por ano salvas em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\estatisticas_ano.csv\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular estatísticas univariadas usando o método describe()\n",
    "def estatisticas_unificadas(data):\n",
    "    resultados = {}\n",
    "\n",
    "    # Estatísticas por dia da semana\n",
    "    data['Dia da Semana'] = data['DATA RECEBIMENTO MANIFESTO'].dt.day_name()\n",
    "    estatisticas_dia_semana = data.groupby('Dia da Semana')['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].describe().reset_index()\n",
    "    resultados['dia_semana'] = estatisticas_dia_semana\n",
    "\n",
    "    # Estatísticas por mês do ano\n",
    "    data['Mês'] = data['DATA RECEBIMENTO MANIFESTO'].dt.month\n",
    "    estatisticas_mes = data.groupby('Mês')['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].describe().reset_index()\n",
    "    resultados['mes'] = estatisticas_mes\n",
    "\n",
    "    # Estatísticas por ano (2016 a 2023)\n",
    "    data['Ano'] = data['DATA RECEBIMENTO MANIFESTO'].dt.year\n",
    "    estatisticas_ano = data[(data['Ano'] >= 2016) & (data['Ano'] <= 2023)].groupby('Ano')['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].describe().reset_index()\n",
    "    resultados['ano'] = estatisticas_ano\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Função para executar a análise e salvar em .csv de forma separada\n",
    "def analise_estatisticas_unificadas(data, path_fig_atv3):\n",
    "    estatisticas_completas = estatisticas_unificadas(data)\n",
    "\n",
    "    # Salvar os arquivos .csv em UTF-8 com BOM\n",
    "    csv_dia_semana = os.path.join(path_fig_atv3, 'estatisticas_dia_semana.csv')\n",
    "    csv_mes = os.path.join(path_fig_atv3, 'estatisticas_mes.csv')\n",
    "    csv_ano = os.path.join(path_fig_atv3, 'estatisticas_ano.csv')\n",
    "\n",
    "    estatisticas_completas['dia_semana'].to_csv(csv_dia_semana, index=False, encoding='utf-8-sig')\n",
    "    estatisticas_completas['mes'].to_csv(csv_mes, index=False, encoding='utf-8-sig')\n",
    "    estatisticas_completas['ano'].to_csv(csv_ano, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Estatísticas por dia da semana salvas em: {csv_dia_semana}\")\n",
    "    print(f\"Estatísticas por mês salvas em: {csv_mes}\")\n",
    "    print(f\"Estatísticas por ano salvas em: {csv_ano}\")\n",
    "\n",
    "# Executar a análise para Florianópolis\n",
    "analise_estatisticas_unificadas(data, path_fig_atv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d8995-bfa9-4bc4-a3b8-faa27fb88396",
   "metadata": {},
   "source": [
    "Sazonalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca64872b-b471-450e-9847-ff3bfebd951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimador de Thiel-Sen: Inclinação=94.5420 ton/mês, Intercepto=846.0623\n",
      "Figura de análise de tendência (Thiel-Sen) salva em: C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3\\tendencia_thiel_sen_residuos_gerados.png\n"
     ]
    }
   ],
   "source": [
    "# Função para agregar resíduos por mês e ano\n",
    "def agregar_residuos_gerados(data):\n",
    "    data['Ano'] = data['DATA RECEBIMENTO MANIFESTO'].dt.year\n",
    "    data['Mês'] = data['DATA RECEBIMENTO MANIFESTO'].dt.month\n",
    "    residuos_mensais_gerados = data.groupby(['Ano', 'Mês'])['QUANTIDADE GERADOS RESIDUOS (TONELADAS)'].sum().reset_index()\n",
    "\n",
    "    # Criar coluna de data para série temporal\n",
    "    residuos_mensais_gerados = residuos_mensais_gerados.rename(columns={'Ano': 'year', 'Mês': 'month'})\n",
    "    residuos_mensais_gerados['Data'] = pd.to_datetime(residuos_mensais_gerados.assign(day=1)[['year', 'month', 'day']])\n",
    "\n",
    "    return residuos_mensais_gerados\n",
    "\n",
    "# Função para calcular o estimador de Thiel-Sen\n",
    "def thiel_sen_estimador(series):\n",
    "    X = np.arange(len(series)).reshape(-1, 1)\n",
    "    y = series.values\n",
    "    model = TheilSenRegressor().fit(X, y)\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    return slope, intercept\n",
    "\n",
    "# Função para analisar tendência com o Estimador de Thiel-Sen\n",
    "def analise_tendencia_thiel_sen(data, path_fig_atv3):\n",
    "    residuos_mensais_gerados = agregar_residuos_gerados(data)\n",
    "\n",
    "    # Série temporal de resíduos gerados\n",
    "    series = residuos_mensais_gerados.set_index('Data')['QUANTIDADE GERADOS RESIDUOS (TONELADAS)']\n",
    "\n",
    "    # Estimador de Thiel-Sen\n",
    "    slope, intercept = thiel_sen_estimador(series)\n",
    "    print(f\"Estimador de Thiel-Sen: Inclinação={slope:.4f} ton/mês, Intercepto={intercept:.4f}\")\n",
    "\n",
    "    # Criar uma análise para incluir na figura\n",
    "    analise = (\n",
    "        f\"$\\\\bf{{Inclinação\\\\ do\\\\ Estimador\\\\ de\\\\ Thiel\\\\text{{-}}Sen:}}$ {slope:.4f} ton/mês.\\n\"\n",
    "        \"Isso indica que, em média, os resíduos gerados estão aumentando\\n\"\n",
    "        \"94,54 toneladas a cada mês, no período de 2016 a 2023.\"\n",
    "    )\n",
    "\n",
    "    # Plotar série temporal com tendência\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(series.index, series, label='Resíduos Gerados', color='blue')\n",
    "\n",
    "    # Adicionar a linha de tendência (Thiel-Sen)\n",
    "    tendencia = intercept + slope * np.arange(len(series))\n",
    "    plt.plot(series.index, tendencia, label='Tendência (Thiel-Sen)', color='red', linestyle='--')\n",
    "\n",
    "    # Adicionar a explicação no canto superior esquerdo em um único box\n",
    "    plt.text(0.02, 0.95, analise, transform=plt.gca().transAxes, fontsize=10,\n",
    "             bbox=dict(facecolor='white', alpha=0.8), verticalalignment='top',\n",
    "             horizontalalignment='left')\n",
    "\n",
    "    plt.title('Análise de Tendência - Estimador de Thiel-Sen')\n",
    "    plt.xlabel('Anos')\n",
    "    plt.ylabel('Quantidade de Resíduos Gerados (Toneladas)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(axis='y', linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "    # Salvar figura\n",
    "    fig_name = os.path.join(path_fig_atv3, 'tendencia_thiel_sen_residuos_gerados.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Figura de análise de tendência (Thiel-Sen) salva em: {fig_name}\")\n",
    "\n",
    "# Caminho para salvar as figuras\n",
    "path_fig_atv3 = r'C:\\Users\\CPDI\\Documents\\GitHub\\ENS410064\\Dados_Entrada\\Figuras_atv3'\n",
    "\n",
    "# Executar a análise\n",
    "analise_tendencia_thiel_sen(data, path_fig_atv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b0158-0873-4cc6-96c6-69215fdc3315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
